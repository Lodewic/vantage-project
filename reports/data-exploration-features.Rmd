---
title: "Grouped-variables"
author: "Lodewic van Twillert"
date: "10/24/2018"
output: 
  html_document:
    fig_caption: yes
    theme: cerulean
    toc_float: yes
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE)
```

```{r libraries}
# Load libraries
library(tidyverse)
library(broom)
library(ggthemes)
library(DT)
library(knitr)
```

```{r Load data}
# Read the raw data
data <- read.csv("../data/raw/water_pump_set.csv")
labels <- read.csv("../data/raw/water_pump_labels.csv")
features <- read.csv("../data/raw/water_pump_features.csv")

# Merge labels and features into single dataset by id
df <- merge(data, labels, by="id")

# Let's add some more info to the feature info using tidyverse piping
feature_desc <- features %>% filter(Feature %in% colnames(data)) %>%
  mutate(example = sapply(data[1, -1], as.character), # First row of the data without the 'id' column
       unique = map_int(data[,-1],function(x) length(unique(x))),
       type = map_chr(data[,-1], function(x) class(unlist(x))), # 
       nonzero = map_int(data[,-1], function(x) sum(as.character(x) != "0")), # Nonzero values, assuming 0 usually means NA
       max_single = map_int(data[,-1], function(x) max(table(x))),      # Observations of most occuring value
       max_occurence = map_chr(data[,-1], function(x) names(which.max(table(x))))) # Highest occuring value
                                 
```

## Features

Each waterpump is described by 39 features and a unique id.
The basic steps of this project are to understand the available features and think about which of these we will have to include, exclude or transform before setting up a predictive model. 

```{r Add additional info to feature description}
# Let's add some more info to the feature info using tidyverse piping
feature_desc <- features %>% filter(Feature %in% colnames(data)) %>%
  mutate(example = sapply(data[1, -1], as.character), # First row of the data without the 'id' column
         unique = map_int(data[,-1],function(x) length(unique(x))),
         type = map_chr(data[,-1], function(x) class(unlist(x))), # 
         nonzero = map_int(data[,-1], function(x) sum(as.character(x) != "0")), # Nonzero values, assuming 0 usually means NA
         max_single = map_int(data[,-1], function(x) max(table(x))),      # Observations of most occuring value
         max_occurence = map_chr(data[,-1], function(x) names(which.max(table(x))))) # Highest occuring value
                                 
# Let's glance at the numeric values in the dataset                               
feature_desc %>% filter(type %in% c("numeric", "integer")) %>% kable()              
feature_desc %>% filter(!type %in% c("numeric", "integer")) %>% kable()
```

### Interpreting feature descriptions

The early stages of a data science project mostly test your common sense. In this instance, we need to determine which
features need to be looked at further.

What to look for in the tables above..

  - Categorical variables with many unique values
  - Continuous variables with a high max_occurence (usually missing values!)
  
Also remember that EVERY categorical value with many unique values are problematic for fitting
classification models. So in any case we should give these a good look.

## Handling feature groups

The variables in the data are far from independent, some variables practically mean the same thing.
Some feature groups are so painfully obvious that we should clean these manually before moving on to
more generic analyses.

In the `Description` column, we can see some overlap in values. These features are likely to represent the same
variable, so we can reduce the dimensionality of the dataset just by smartly combining some variables.

Let's start with common sense and group some of the variables manually to prepare the data
for more automated pipelines. Here are some logical groups we can check,

  - scheme_name, scheme_management, installer, funder
  - extraction_type, extraction_type_group, extraction_type_class
  - management, management_group
  - scheme_management, scheme_name
  - payment, payment_type
  - water_quality, quality_group
  - quantity_quantity_group
  - source, source_class
  - waterpoint_type, waterpoint_type_group
  
Note how these variables are the majority of all non-numeric features.
  
### Conclusion of groups

Now, you could look into each variable group to determine what we did. But for clarify, and to save your scrollwheel,
here is the conclusion up front.

**Remove 9 features**

  - `scheme_name`, `scheme_management` ,    too many unique
  - `extraction_type_group`,    overlaps with `extraction_type` and `extraction_class`
  - `funder` and `installer`,   many missing values, unique values and data-entry inconsistencies
  - `source_class`, `payment`, `waterpoint_type_group`, `management_group` because they are duplicates of other variables
    
**Edit 1 feature**

  - `extraction_type`,  rename some similar categories with very low occurences

Let's make a note of these findings. We will cleanly integrate these steps into our data preprocessing pipeline.
  
### Scheme_name, scheme_management, installer, funder
 
These 4 features have far too many unique values to be used as categorical labels.
In some cases we can bin groups by grouping the least occurring data as 'other', but 
in these cases the arity is too high.

Together with spelling errors in these labels we won't spend the effort to transform
these values into something more useful with text processing.
 
```{r scheme management table}
data %>% 
    select(scheme_name, scheme_management, installer, funder) %>%
    mutate_all(as.character) %>%
    mutate_all(tolower) %>% # To lowercase since there are many typing 'errors' or inconsistencies
    group_by(scheme_name, scheme_management, installer, funder) %>%
    tally() %>% 
    arrange(desc(n)) %>% 
    head(10) %>%
    kable()
```

The scheme names are a mess. There are non-ambiguous names, spelling errors,
numeric values, etc. Values such as like 'Adra', 'ADRA', 'WOULD BANK', etc.. are
variations on each other. We can reduce this already by using the lowercase version, 
but not enough to warrant the inclusion of this variable.

```{r scheme name table}
# Scheme names
data %>% select(scheme_name) %>% table() %>% sort(decreasing = T) %>% head()
# Half the data is missing data, and the rest is extremely scattered
# Furthermore there are many unambiguous names and spelling errors like 'Adra', 'ADRA', 'WOULD BANK', etc..
df %>%
    filter(scheme_name != "") %>%
    group_by(scheme_name, status_group) %>%
    tally() %>% head(20) %>%
    kable()
# Based on this we remove the scheme_name entirely
```

```{r}
# Scheme management
data %>% select(scheme_management) %>% table() %>% sort(decreasing = T) %>% 
  head() %>% kable()

# Plot label per scheme_management
df %>% select(scheme_management, status_group) %>%
    ggplot(aes(x = scheme_management, fill = status_group)) +
    geom_bar() + coord_flip() +
    ggtitle("Water pomp status voor management_scheme") +
    theme_fivethirtyeight()

# Most of the water pumps are from a handful of installers. 
# We could consider grouping all the low occurences into a group 'other'
# Plot label per scheme_management
scheme_management_groups = df %>% select(scheme_management, status_group) %>%
    group_by(scheme_management) %>%
    tally() %>%
    top_n(10, n) 

cat(sprintf("Scheme management in 10 groups accounts for %1.2f%% of the data. And just VWC is %1.2f%%", 
            100 * sum(scheme_management_groups$n) / nrow(df),
            100 * max(scheme_management_groups$n) / nrow(df)))
```

#### Installer and funder

The installer and funder values have many levels. Again a lot of data-entry errors
seem apparent in the data, and when transformed to lower-case the installer and funder
variables overlap for over 50%. Because of the arity of this data we remove both.

  - Possible to do string matching

```{r}
# installer
data %>% select(installer) %>% table() %>% sort(decreasing = T) %>% head()
length(unique(data$installer))

# Most of the water pumps are from a handful of installers. 
# We could consider grouping all the low occurences into a group 'other'
# Plot label per scheme_management
installer_groups = df %>% select(installer, status_group) %>%
    group_by(installer) %>%
    tally() %>%
    top_n(20, n)

# Plot installer versus status_group to verify 
df %>% select(installer, status_group) %>%
    mutate(installer = ifelse(installer %in% installer_groups$installer, as.character(installer), "other"),
           installer = ifelse(installer %in% c("", "0"), "unknown", installer)) %>%
    ggplot(aes(x = installer, fill = status_group)) +
    geom_bar() + coord_flip() +
    ggtitle("Water pomp status voor installer", subtitle = "Kleine groepen samengevoegd in 'other'") +
    theme_fivethirtyeight() 

# Show counts of installer labes, only top20
# Notice that many of these have about the same number of observations and grouping all the others into
# 'other' is quite arbitrary since the 'other' group will still be half the data. 
# The number of 'larger' groups and the number of spelling errors in the data require more detailed feature engineering
# like some kind of string matching- which we will not spend our time on.
# THIS FEATURE WILL BE REMOVED FROM THE MODELLING DATA
```

```{r}
# funder
data %>% select(funder) %>% table() %>% sort(decreasing = T) %>% head() %>% kable()

cat(sprintf("Of the %i unique funder names, %i overlap with the installer names!",
            length(unique(data$funder)),
            length(intersect(tolower(as.character(data$funder)), tolower(as.character(data$installer))))))
# Due to the high overlap between funder and installer, we can assume that these two are heavily related and 
# will probably give us the same difficulty as the funder names by themselves.
# WE REMOVE THIS FEATURE FROM THE DATASET!
```

### Extraction types

```{r Show extraction types}
# Groups for each extraction type to determine which has the most information
df %>% select(extraction_type, extraction_type_group, extraction_type_class) %>%
  apply(2, function(x) length(unique(x)))

# Count label co-occurences to potentially remove some features as we have a 
# tractable number of features (not 100s this time!)
df %>%
    group_by(extraction_type, extraction_type_group, extraction_type_class) %>%
    tally() %>% kable()
```

By far the most prevalent type of waterpump is the gravity water pump type. This type of pump is eco-friendly as it does not use energy other than gravity.

Notice that there are some very small groups in the data,  mostly due to the inclusion of `extraction_type`. The `extraction_type` has some values that we could combine with other categories to reduce the dimensionality.

  - **india mark ii** and **india mark iii** can be combined to just **india mark**
  - **cemo** and **climax** are just two types of motorpumps, let's not differentiate these two
  - **other - mkulima/shinyanga** is very specific, we can just classify this as handpump together with **play pump** and **walimi**
  - Lastly the **swn 81** and **swn 80** are both handpumps, we can classifiy these as **swn**
      * The SWN 80 and SWN 81 type of handle pumps only differ in their pump head so that the SWN 81 can reach deeper wells. [Read more about handpumps here:)](https://www.ircwash.org/sites/default/files/232.2-13249.pdf)
      * Fun fact, the SWN stands for 'Sociale Werkplaats Nunspeet'! The SWN family of pumps was introduced partly by a workshop for the handicapped in the Netherlands sine 1976.

Let's manually combine some of the feature groups into related groups.

```{r}
# Temporary data about the extraction type
df_extraction <- df %>% 
    mutate(
        extraction_type = as.character(extraction_type),
        extraction_type = ifelse(extraction_type %in% c("india mark ii", "india mark iii"), "india mark", extraction_type),
        extraction_type = ifelse(extraction_type %in% c("cemo", "climax"), "motorpump", extraction_type),
        extraction_type = ifelse(extraction_type %in% c("other - swn 81", "swn 80"), "swn", extraction_type),
        extraction_type = ifelse(extraction_type %in% c('other - mkulima/shinyanga','other - play pump', 'walimi'), "handpump", extraction_type)
           ) %>%
    select(id, extraction_type, extraction_type_class)

df_extraction %>% group_by(extraction_type, extraction_type_class) %>% tally() %>% kable()

# Make a new table of group counts
df_extraction %>% 
    mutate(extraction_group = paste(extraction_type, extraction_type_class, sep="-")) %>%
    group_by(extraction_group, extraction_type, extraction_type_class) %>%
    tally() %>%
    arrange(n) %>%
    ungroup() %>%
    mutate(extraction_type = factor(extraction_type, levels=extraction_type)) %>% # Relevel to reorder plot
    ggplot(aes(x = extraction_type, y = n, label = n, fill = extraction_type_class)) +
        geom_bar(stat="identity", position="dodge") + 
        ggtitle("Water pomp types na combineren van groepen") +
        geom_text() + coord_flip() + theme_fivethirtyeight()
```

Using two out of three extraction types, after some adjustments, in the data we can classify all the data in a way that none of the groups is truly underrepresented.

### management and management_group

These two variables seem to mean the exact same thing.

```{r}
# Cross table of only two variables
df %>% group_by(management, management_group) %>% tally() %>% knitr::kable()
# The management variable has more information than management_group
```

We will select the column with *more* information, so we keep the `management` variable and drop the `management_group`.

### Payment and payment_type

The payment and payment type columns also mean the exact same thing.

```{r payment types}
# Cross table of only two variables
df %>% group_by(payment, payment_type) %>% tally() %>% kable()
# The payments are exactly the same, we can drop either one.
```

The payment_type variables are more concise so we will drop the `payment` column.

### Water quality and quality group

```{r water quality}
# Cross table of only two variables
df %>% group_by(water_quality, quality_group) %>% tally() %>% kable()
```

```{r quality vs status}
# Is water quality correlated to the water pump status?
df %>% group_by(water_quality, status_group) %>%
    tally() %>%
    group_by(water_quality) %>% mutate(n = n / sum(n)) %>%
    filter(water_quality != "soft") %>%
    ggplot(aes(x = water_quality, y = n, fill = status_group)) +
    geom_bar(stat="identity") + coord_flip() + 
    ggtitle("Water kwaliteit versus pomp status ratios") +
    theme_fivethirtyeight()
```

The `water_quality` contains more information so we will drop the `quality_group`.

The `water_quality` is also related to the `amount_tsh` in the data, even though we are removing `amount_tsh`(!) The only pumps where a significant amount of water is available is the ones where 'soft' water was found. So even though we are leaving out `amount_tsh`, we will still capture some of its information by including the `water_quality`.

We could improve the visualisation above but it will likely not affect the choices we already made, so let's move on...

### Quantity and quantity_group

The `quantity` and `quantity_group` sounds like they have the same relation as the water quality. Let's check!

```{r water quantity}
# Cross table of only two variables
df %>% group_by(quantity, quantity_group) %>% tally()
```

welp.. we checked, and we'll just leave out the `quantity_group` column. 

### Source, source_class and source_type

The source of water for each waterpoint is encoded in three values.
  
  - source, most detailed definition
  - source_class, 4 categories of all source types
  - source_type, the same as `source` except that unkown=other


```{r}
# Cross table of only two variables
df %>% group_by(source, source_class, source_type) %>% tally()
```

The water `source` is more detailed than `source_class` and contains the exact same values as `source_type`. So let's keep only the `source` and `source_type`.
However, the `source_class` contains only 3 categories and this more general distinction may in fact help us make predictions.
We can calculate the feature importance later, so let's keep both variables in our data and verify whether inclusion of `source_class` improves the model at all.

Alternatively, is the water quality correlated at all to water pump status?

```{r}

# Is water quality correlated to the water pump status?
df %>% group_by(source, source_class, status_group) %>%
    tally() %>%
    group_by(source) %>% mutate(n = n / sum(n)) %>%
    ggplot(aes(x = source, y = n, fill = status_group)) +
    geom_bar(stat="identity") + coord_flip() + 
    ggtitle("Water bron versus pomp status ratios") +
    theme_fivethirtyeight()
```

The source is definitely not a perfect prediction of water pump status, but at least a distinction between classes could be beneficial. It remains to be seen whether the water source is truly indicative of the water pump status, why would a pump near a lake be more likely to be non-functional than that near a spring? Unless the water source has dried up, but this would rather affect multiple pumps in the same area.

If there was more time available we could find if there is just a cluster of water pumps at a single lake that are non-functional because of regional differences, for example. The location of a pump probably determines the water source, and since we will already take the gps-coordinates into account we might not be including any new information with the `source` feature.

### Waterpoint_type and waterpoint_type_group

Finally, this group of two variables may be reduced to a single variable.
They are once again the exacty same feature.

```{r}
# Cross table of only two variables
df %>% group_by(waterpoint_type, waterpoint_type_group) %>% tally()
```


## Contiuous variables

Now that we have removed and changed some of the overlapping labels, we are left with the following features.

### Conclusion

Again let us start with the conclusion!

**Remove**

  - `amount_tsh`
  - `num_private`
  - `

### amount_tsh 

The amount of water available to the water pump seems like an important feature, but it only consists of 98 unique values!
Let's see what is going on here.

```{r}
# Plot amount_tsh as barplot
table(df$amount_tsh)[1:10]
# Most of the values are 0
```

Ah, there are many `0` values in the data. Based on all the other values of this feature
it does not seem likely that `0` always indicates a missing value; `0` seems like it can be a possible value. However,
there is no way to differentiate between missing values and dry water pumps.

For now we remove this data from our cleaned data because of the large number of 'missing' values.

### GPS coordinates

There are three types of gps coordinates in the data,

  - gps_height
  - longitude
  - latitude

We expect these to be continuous values.

```{r}
# See which gps coordinates occur more than once
df %>% group_by(gps_height, longitude, latitude) %>%
  tally() %>% filter(n > 2) %>% kable()
```

Of all the observations we only find that 1812 observations are missing values, where
gps_height, longitude and latitude are all 0.

We could try to deal with these values in a number of ways,

  - Impute values based on other location data (region_code, district, basin, etc.)
  - Ignore missing values as it only comprises small part of the data
  - At least center the water pumps to somewhere in Tanzania
  
Of course this has varying levels of complexity and for now we simply ignore  missing values
and leave them as is. I do not think that the GPS data adds any new information since all location data
is already encoded in various ways using district and region codes. 

I have seen others impute these values, even the gps_height, but imputing GPS data 
with the available is far fetched to me.

### num_private

num_private comes without a feature description, but with a lot of zero-values.

```{r table of num_private}
num_private_tbl <- table(df$num_private)[1:10]
```

We will remove `num_private` from the data since `r 100*num_private_tbl[1] / nrow(df)`% of the observations is zero/missing.

### construction_year

Missing values of `construction_year` are indicated by zero-values. How to replace these is not necessarily straightforward since we treat this as a continuous variable! Since the difference between 1955 and 2000 is much smaller than 1955 and 0 we should be careful here! If the construction year is predictive of the water pump status then zero-values will likely introduce a bias.

There are a TON of missing values in this variable. But a baseline value such as the median is better than using 0 for missing values.

For missing values we should definitely impute some value. Traditionally the most straightforward way is to just impute the mean or median value. We may correct for region or pump type to improve this imputation. A quick glance at factors that may indicate a missing construction_year we don't find any. So let us use a very simple imputation method to save time.

Furthermore, we're better off to actually add the `age` variable to the data! Simply by calculating the difference between `date_recorded` and `construction_year`.

```{r}
barplot(table(df$construction_year), main="Distribution of construction_year")
```

## High number of categories

Some variables have an extreme amount of categories.

  - subvillage, `r length(unique(df$subvillage))` unique values
  - lga, `r length(unique(df$lga))` unique values
  - ward, `r length(unique(df$ward))` unique values
  
Upon closer inspection, from the `lga` variable we can infer some information!

```{r}
table(df$lga)[1:10]
```
Some of these values indicate a placename, and since we already have GPS coordinates, region codes and district codes we 
do not find any additional information in this feature. However...!

Noticate how some of the `lga` values above end with **urban** or **rural**!
We can create new variable called `urban_rural` with the levels,

  - rural
  - urban
  - other
  
This new feature may be more informative than raw `lga`. So in our pipeline we have
added this transformation.

## ..........

More exploratory steps were lost when cleaning up files before syncing with git.
While I still remember the findings, you will not find them presented here or anywhere sadly.

More analysis was done, including classification using test/training sets split either
at random or by selecting the 'first' 70% of the observations based on the date_recorded, so that
we can better evaluate our predictions of future observations.

